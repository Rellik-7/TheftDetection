{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\nimport cv2\nimport os\nimport numpy as np\nimport keras\nimport matplotlib.pyplot as plt\n# import download\nfrom random import shuffle\nfrom tensorflow.keras.applications import MobileNet\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense, Activation\nimport sys\nimport h5py","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:30:54.642734Z","iopub.execute_input":"2022-07-10T13:30:54.643263Z","iopub.status.idle":"2022-07-10T13:30:54.655888Z","shell.execute_reply.started":"2022-07-10T13:30:54.643225Z","shell.execute_reply":"2022-07-10T13:30:54.655000Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Functions to display progress of processing","metadata":{}},{"cell_type":"code","source":"def print_progress(count, max_count):\n    # Percentage completion.\n    pct_complete = count / max_count\n\n    # Status-message.\n    msg = \"\\r- Progress: {0:.1%}\".format(pct_complete)\n    sys.stdout.write(msg)\n    sys.stdout.flush()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-10T13:30:54.674942Z","iopub.execute_input":"2022-07-10T13:30:54.676303Z","iopub.status.idle":"2022-07-10T13:30:54.682781Z","shell.execute_reply.started":"2022-07-10T13:30:54.676260Z","shell.execute_reply":"2022-07-10T13:30:54.681900Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"#Trained on kaggle, alter input link\n# in_dir = \"../input/hockey-fight-vidoes/data\"","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:30:54.706717Z","iopub.execute_input":"2022-07-10T13:30:54.707219Z","iopub.status.idle":"2022-07-10T13:30:54.711960Z","shell.execute_reply.started":"2022-07-10T13:30:54.707183Z","shell.execute_reply":"2022-07-10T13:30:54.710745Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Frame size  \nimg_size = 224\n\nimg_size_tuple = (img_size, img_size)\n\n# Number of channels (RGB)\nnum_channels = 3\n\n# Flat frame size\nimg_size_flat = img_size * img_size * num_channels\n\n# Number of classes for classification (Violence-No Violence)\nnum_classes = 2\n\n# Number of files to train\n_num_files_train = 1\n\n# Number of frames per video\n_images_per_file = 20\n\n# Number of frames per training set\n_num_images_train = _num_files_train * _images_per_file\n\n# Video extension\nvideo_exts = \".avi\"","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:30:54.738080Z","iopub.execute_input":"2022-07-10T13:30:54.738331Z","iopub.status.idle":"2022-07-10T13:30:54.743530Z","shell.execute_reply.started":"2022-07-10T13:30:54.738309Z","shell.execute_reply":"2022-07-10T13:30:54.742563Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# We get 20 frames per video","metadata":{}},{"cell_type":"code","source":"def get_frames(current_dir, file_name):\n    in_file = os.path.join(current_dir, file_name)\n    images = []\n    vidcap = cv2.VideoCapture(in_file)\n    success,image = vidcap.read()\n    count = 0\n    while count<_images_per_file:    \n        RGB_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        res = cv2.resize(RGB_img, dsize=(img_size, img_size),\n                                 interpolation=cv2.INTER_CUBIC)\n        images.append(res)\n        success,image = vidcap.read()\n        count += 1\n        \n    result = np.array(images)\n    \n    result = (result / 255.).astype(np.float16)\n        \n    return result","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:30:54.767618Z","iopub.execute_input":"2022-07-10T13:30:54.768180Z","iopub.status.idle":"2022-07-10T13:30:54.776237Z","shell.execute_reply.started":"2022-07-10T13:30:54.768142Z","shell.execute_reply":"2022-07-10T13:30:54.775330Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"#Label videos\ndef label_video_names(in_dir):\n    names = []\n    # list containin video labels [1, 0] if it has violence and [0, 1] if not\n    labels = []\n    for current_dir, dir_names,file_names in os.walk(in_dir):\n        for file_name in file_names:\n            if file_name[0:2] == 'fi':\n                labels.append([1,0])\n                names.append(file_name)\n            elif file_name[0:2] == 'no':\n                labels.append([0,1])\n                names.append(file_name) \n    c = list(zip(names,labels))\n    # Shuffle the data (names and labels)\n    shuffle(c)\n    names, labels = zip(*c) \n    return names, labels","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:30:54.795820Z","iopub.execute_input":"2022-07-10T13:30:54.796618Z","iopub.status.idle":"2022-07-10T13:30:54.803429Z","shell.execute_reply.started":"2022-07-10T13:30:54.796581Z","shell.execute_reply":"2022-07-10T13:30:54.802284Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"names, labels = label_video_names(in_dir)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:30:54.818903Z","iopub.execute_input":"2022-07-10T13:30:54.820456Z","iopub.status.idle":"2022-07-10T13:30:54.875824Z","shell.execute_reply.started":"2022-07-10T13:30:54.820421Z","shell.execute_reply":"2022-07-10T13:30:54.875016Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Model: VGG16 + LSTM","metadata":{}},{"cell_type":"code","source":"image_model = VGG16(include_top=True, weights='imagenet')","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:30:54.877614Z","iopub.execute_input":"2022-07-10T13:30:54.878022Z","iopub.status.idle":"2022-07-10T13:30:56.681263Z","shell.execute_reply.started":"2022-07-10T13:30:54.877987Z","shell.execute_reply":"2022-07-10T13:30:56.680257Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"transfer_layer = image_model.get_layer('fc2')\n\nimage_model_transfer = Model(inputs=image_model.input,\n                             outputs=transfer_layer.output)\n\ntransfer_values_size = K.int_shape(transfer_layer.output)[1]","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:30:56.682736Z","iopub.execute_input":"2022-07-10T13:30:56.683101Z","iopub.status.idle":"2022-07-10T13:30:56.694558Z","shell.execute_reply.started":"2022-07-10T13:30:56.683043Z","shell.execute_reply":"2022-07-10T13:30:56.693419Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def get_transfer_values(current_dir, file_name):\n    \n    # Pre-allocate input-batch-array for images.\n    shape = (_images_per_file,) + img_size_tuple + (3,)\n    image_batch = np.zeros(shape=shape, dtype=np.float16)\n    image_batch = get_frames(current_dir, file_name)\n      \n    # Pre-allocate output-array for transfer-values.\n    shape = (_images_per_file, transfer_values_size)\n    transfer_values = np.zeros(shape=shape, dtype=np.float16)\n\n    transfer_values = \\\n            image_model_transfer.predict(image_batch)\n    return transfer_values","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:30:56.697356Z","iopub.execute_input":"2022-07-10T13:30:56.698446Z","iopub.status.idle":"2022-07-10T13:30:56.705254Z","shell.execute_reply.started":"2022-07-10T13:30:56.698410Z","shell.execute_reply":"2022-07-10T13:30:56.704248Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Function to process one video of 20 frames through CNN\ndef process_transfer(vid_names, in_dir, labels):\n    count = 0\n    tam = len(vid_names)\n    # Pre-allocate input-batch-array for images.\n    shape = (_images_per_file,) + img_size_tuple + (3,)\n    while count<tam:\n        video_name = vid_names[count]\n        image_batch = np.zeros(shape=shape, dtype=np.float16)\n        image_batch = get_frames(in_dir, video_name)\n        shape = (_images_per_file, transfer_values_size)\n        transfer_values = np.zeros(shape=shape, dtype=np.float16)\n        transfer_values = \\\n            image_model_transfer.predict(image_batch)\n        labels1 = labels[count]\n        aux = np.ones([20,2])\n        labelss = labels1*aux\n        yield transfer_values, labelss\n        count+=1","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:30:56.706580Z","iopub.execute_input":"2022-07-10T13:30:56.707499Z","iopub.status.idle":"2022-07-10T13:30:56.717264Z","shell.execute_reply.started":"2022-07-10T13:30:56.707463Z","shell.execute_reply":"2022-07-10T13:30:56.716108Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"# Save CNN transfer values","metadata":{}},{"cell_type":"code","source":"def make_files(n_files):\n    \n    gen = process_transfer(names_training, in_dir, labels_training)\n\n    numer = 1\n\n    # Read the first chunk to get the column dtypes\n    chunk = next(gen)\n\n    row_count = chunk[0].shape[0]\n    row_count2 = chunk[1].shape[0]\n    \n    with h5py.File('prueba.h5', 'w') as f:\n    \n        # Initialize a resizable dataset to hold the output\n        maxshape = (None,) + chunk[0].shape[1:]\n        maxshape2 = (None,) + chunk[1].shape[1:]\n    \n    \n        dset = f.create_dataset('data', shape=chunk[0].shape, maxshape=maxshape,\n                                chunks=chunk[0].shape, dtype=chunk[0].dtype)\n    \n        dset2 = f.create_dataset('labels', shape=chunk[1].shape, maxshape=maxshape2,\n                                 chunks=chunk[1].shape, dtype=chunk[1].dtype)\n    \n         # Write the first chunk of rows\n        dset[:] = chunk[0]\n        dset2[:] = chunk[1]\n\n        for chunk in gen:\n            \n            if numer == n_files:\n            \n                break\n\n            # Resize the dataset to accommodate the next chunk of rows\n            dset.resize(row_count + chunk[0].shape[0], axis=0)\n            dset2.resize(row_count2 + chunk[1].shape[0], axis=0)\n\n            # Write the next chunk\n            dset[row_count:] = chunk[0]\n            dset2[row_count:] = chunk[1]\n\n            # Increment the row count\n            row_count += chunk[0].shape[0]\n            row_count2 += chunk[1].shape[0]\n            \n            print_progress(numer, n_files)\n        \n            numer += 1","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:30:56.719047Z","iopub.execute_input":"2022-07-10T13:30:56.719738Z","iopub.status.idle":"2022-07-10T13:30:56.732964Z","shell.execute_reply.started":"2022-07-10T13:30:56.719702Z","shell.execute_reply":"2022-07-10T13:30:56.731884Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def make_files_test(n_files):\n    \n    gen = process_transfer(names_test, in_dir, labels_test)\n\n    numer = 1\n\n    # Read the first chunk to get the column dtypes\n    chunk = next(gen)\n\n    row_count = chunk[0].shape[0]\n    row_count2 = chunk[1].shape[0]\n    \n    with h5py.File('pruebavalidation.h5', 'w') as f:\n    \n        # Initialize a resizable dataset to hold the output\n        maxshape = (None,) + chunk[0].shape[1:]\n        maxshape2 = (None,) + chunk[1].shape[1:]\n    \n    \n        dset = f.create_dataset('data', shape=chunk[0].shape, maxshape=maxshape,\n                                chunks=chunk[0].shape, dtype=chunk[0].dtype)\n    \n        dset2 = f.create_dataset('labels', shape=chunk[1].shape, maxshape=maxshape2,\n                                 chunks=chunk[1].shape, dtype=chunk[1].dtype)\n    \n         # Write the first chunk of rows\n        dset[:] = chunk[0]\n        dset2[:] = chunk[1]\n\n        for chunk in gen:\n            \n            if numer == n_files:\n            \n                break\n\n            # Resize the dataset to accommodate the next chunk of rows\n            dset.resize(row_count + chunk[0].shape[0], axis=0)\n            dset2.resize(row_count2 + chunk[1].shape[0], axis=0)\n\n            # Write the next chunk\n            dset[row_count:] = chunk[0]\n            dset2[row_count:] = chunk[1]\n\n            # Increment the row count\n            row_count += chunk[0].shape[0]\n            row_count2 += chunk[1].shape[0]\n            \n            print_progress(numer, n_files)\n        \n            numer += 1","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:30:56.736196Z","iopub.execute_input":"2022-07-10T13:30:56.736925Z","iopub.status.idle":"2022-07-10T13:30:56.750327Z","shell.execute_reply.started":"2022-07-10T13:30:56.736891Z","shell.execute_reply":"2022-07-10T13:30:56.749351Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# Train Test Split","metadata":{}},{"cell_type":"code","source":"training_set = int(len(names)*0.8)\ntest_set = int(len(names)*0.2)\n\nnames_training = names[0:training_set]\nnames_test = names[training_set:]\n\nlabels_training = labels[0:training_set]\nlabels_test = labels[training_set:]","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:30:56.752079Z","iopub.execute_input":"2022-07-10T13:30:56.752687Z","iopub.status.idle":"2022-07-10T13:30:56.764619Z","shell.execute_reply.started":"2022-07-10T13:30:56.752651Z","shell.execute_reply":"2022-07-10T13:30:56.763534Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"# Cache transfer values","metadata":{}},{"cell_type":"code","source":"make_files(training_set)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:30:56.769323Z","iopub.execute_input":"2022-07-10T13:30:56.770009Z","iopub.status.idle":"2022-07-10T13:33:12.820304Z","shell.execute_reply.started":"2022-07-10T13:30:56.769973Z","shell.execute_reply":"2022-07-10T13:33:12.819299Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"make_files_test(test_set)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:33:12.822994Z","iopub.execute_input":"2022-07-10T13:33:12.823467Z","iopub.status.idle":"2022-07-10T13:33:44.845961Z","shell.execute_reply.started":"2022-07-10T13:33:12.823419Z","shell.execute_reply":"2022-07-10T13:33:44.845040Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"# We load cached data, so we can alter RNN without need for CNN again","metadata":{}},{"cell_type":"code","source":"def process_alldata_training():\n    \n    joint_transfer=[]\n    frames_num=20\n    count = 0\n    \n    with h5py.File('prueba.h5', 'r') as f:\n            \n        X_batch = f['data'][:]\n        y_batch = f['labels'][:]\n\n    for i in range(int(len(X_batch)/frames_num)):\n        inc = count+frames_num\n        joint_transfer.append([X_batch[count:inc],y_batch[count]])\n        count =inc\n        \n    data =[]\n    target=[]\n    \n    for i in joint_transfer:\n        data.append(i[0])\n        target.append(np.array(i[1]))\n        \n    return data, target","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:33:44.847305Z","iopub.execute_input":"2022-07-10T13:33:44.847857Z","iopub.status.idle":"2022-07-10T13:33:44.856232Z","shell.execute_reply.started":"2022-07-10T13:33:44.847818Z","shell.execute_reply":"2022-07-10T13:33:44.854992Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def process_alldata_test():\n    \n    joint_transfer=[]\n    frames_num=20\n    count = 0\n    \n    with h5py.File('pruebavalidation.h5', 'r') as f:\n            \n        X_batch = f['data'][:]\n        y_batch = f['labels'][:]\n\n    for i in range(int(len(X_batch)/frames_num)):\n        inc = count+frames_num\n        joint_transfer.append([X_batch[count:inc],y_batch[count]])\n        count =inc\n        \n    data =[]\n    target=[]\n    \n    for i in joint_transfer:\n        data.append(i[0])\n        target.append(np.array(i[1]))\n        \n    return data, target","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:33:44.857498Z","iopub.execute_input":"2022-07-10T13:33:44.858444Z","iopub.status.idle":"2022-07-10T13:33:44.871629Z","shell.execute_reply.started":"2022-07-10T13:33:44.858409Z","shell.execute_reply":"2022-07-10T13:33:44.870249Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"data, target = process_alldata_training()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:33:44.872873Z","iopub.execute_input":"2022-07-10T13:33:44.873318Z","iopub.status.idle":"2022-07-10T13:33:44.997374Z","shell.execute_reply.started":"2022-07-10T13:33:44.873272Z","shell.execute_reply":"2022-07-10T13:33:44.996385Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"data_test, target_test = process_alldata_test()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:33:44.998721Z","iopub.execute_input":"2022-07-10T13:33:44.999053Z","iopub.status.idle":"2022-07-10T13:33:45.036896Z","shell.execute_reply.started":"2022-07-10T13:33:44.999019Z","shell.execute_reply":"2022-07-10T13:33:45.035737Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"LSTM","metadata":{}},{"cell_type":"code","source":"chunk_size = 4096 #Output of vgg16\nn_chunks = 20\nrnn_size = 512\n\nmodel = Sequential()\nmodel.add(LSTM(rnn_size, input_shape=(n_chunks, chunk_size)))\nmodel.add(Dense(1024))\nmodel.add(Activation('relu'))\nmodel.add(Dense(50))\nmodel.add(Activation('sigmoid'))\nmodel.add(Dense(2))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:33:45.038487Z","iopub.execute_input":"2022-07-10T13:33:45.038831Z","iopub.status.idle":"2022-07-10T13:33:45.450940Z","shell.execute_reply.started":"2022-07-10T13:33:45.038794Z","shell.execute_reply":"2022-07-10T13:33:45.449976Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:00:37.499120Z","iopub.execute_input":"2022-07-10T14:00:37.499408Z","iopub.status.idle":"2022-07-10T14:00:37.507461Z","shell.execute_reply.started":"2022-07-10T14:00:37.499382Z","shell.execute_reply":"2022-07-10T14:00:37.506433Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"epoch = 200\nbatchS = 500\n\nhistory = model.fit(np.array(data[0:720]), np.array(target[0:720]), epochs=epoch,\n                    validation_data=(np.array(data[720:]), np.array(target[720:])), \n                    batch_size=batchS, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:33:45.453893Z","iopub.execute_input":"2022-07-10T13:33:45.454659Z","iopub.status.idle":"2022-07-10T13:34:36.714411Z","shell.execute_reply.started":"2022-07-10T13:33:45.454629Z","shell.execute_reply":"2022-07-10T13:34:36.713447Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:34:36.718228Z","iopub.execute_input":"2022-07-10T13:34:36.718506Z","iopub.status.idle":"2022-07-10T13:34:36.741318Z","shell.execute_reply.started":"2022-07-10T13:34:36.718480Z","shell.execute_reply":"2022-07-10T13:34:36.739938Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"# Test model","metadata":{}},{"cell_type":"code","source":"result = model.evaluate(np.array(data_test), np.array(target_test))","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:35:49.136702Z","iopub.execute_input":"2022-07-10T13:35:49.137079Z","iopub.status.idle":"2022-07-10T13:35:49.378589Z","shell.execute_reply.started":"2022-07-10T13:35:49.137034Z","shell.execute_reply":"2022-07-10T13:35:49.377603Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"target_test","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:03:57.079880Z","iopub.execute_input":"2022-07-10T14:03:57.080236Z","iopub.status.idle":"2022-07-10T14:03:57.111549Z","shell.execute_reply.started":"2022-07-10T14:03:57.080206Z","shell.execute_reply":"2022-07-10T14:03:57.110577Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"for name, value in zip(model.metrics_names, result):\n    print(name, value)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:35:51.744571Z","iopub.execute_input":"2022-07-10T13:35:51.744936Z","iopub.status.idle":"2022-07-10T13:35:51.752139Z","shell.execute_reply.started":"2022-07-10T13:35:51.744903Z","shell.execute_reply":"2022-07-10T13:35:51.749920Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('destination_path.eps', format='eps', dpi=1000)\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.savefig('destination_path1.eps', format='eps', dpi=1000)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:35:56.484721Z","iopub.execute_input":"2022-07-10T13:35:56.485087Z","iopub.status.idle":"2022-07-10T13:35:57.968441Z","shell.execute_reply.started":"2022-07-10T13:35:56.485040Z","shell.execute_reply":"2022-07-10T13:35:57.967304Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"model.save(\"cnn_vgg16\")","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:37:53.176955Z","iopub.execute_input":"2022-07-10T13:37:53.177890Z","iopub.status.idle":"2022-07-10T13:37:57.242756Z","shell.execute_reply.started":"2022-07-10T13:37:53.177855Z","shell.execute_reply":"2022-07-10T13:37:57.241796Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"# Deployment","metadata":{}},{"cell_type":"code","source":"def process_gradio(filename):\n    #Get 20 frames\n    frames = get_frames(\"\",filename)\n    #Get CNN transfer values\n    transfer = image_model_transfer.predict(frames)\n    transfer = transfer.reshape(1,transfer.shape[0],transfer.shape[1])\n    print(transfer.shape)\n    #Pass through LSTM\n    out = model.predict(transfer)\n    print(out)\n    #return label [1,0] if violence\n    if(out[0][0] > 0.5):\n        return \"Violence detected\",out[0][0]\n    else:\n        return \"No violence detected\",out[0][1]","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:40:12.800794Z","iopub.execute_input":"2022-07-10T14:40:12.801155Z","iopub.status.idle":"2022-07-10T14:40:12.808410Z","shell.execute_reply.started":"2022-07-10T14:40:12.801125Z","shell.execute_reply":"2022-07-10T14:40:12.807132Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"# !zip -radd_docstring 'cnn_vgg16_hockey.zip' './cnn_vgg16'","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:42:29.700599Z","iopub.execute_input":"2022-07-10T13:42:29.700965Z","iopub.status.idle":"2022-07-10T13:42:35.399926Z","shell.execute_reply.started":"2022-07-10T13:42:29.700936Z","shell.execute_reply":"2022-07-10T13:42:35.398733Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"!pip install gradio\nimport gradio as gr","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:58:09.178825Z","iopub.execute_input":"2022-07-10T13:58:09.179195Z","iopub.status.idle":"2022-07-10T13:58:29.806824Z","shell.execute_reply.started":"2022-07-10T13:58:09.179165Z","shell.execute_reply":"2022-07-10T13:58:29.805867Z"},"scrolled":true,"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# process_gradio(\"../input/hockey-fight-vidoes/data/no115_xvid.avi\")","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:43:44.384017Z","iopub.execute_input":"2022-07-10T14:43:44.388450Z","iopub.status.idle":"2022-07-10T14:43:44.650203Z","shell.execute_reply.started":"2022-07-10T14:43:44.388407Z","shell.execute_reply":"2022-07-10T14:43:44.648872Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"inputs = gr.Video(source = 'upload', label = 'Input video', show_label =  True)\noutputs = [gr.Textbox(label = 'Result', show_label = True),\n           gr.Textbox(label = 'Percentage Accuracy', show_label = True)]\ndemo = gr.Interface(fn = process_gradio, \n                    inputs = inputs, \n                    outputs = outputs,\n                    title = 'Violence Detection Using Conv2D + LSTM Model'\n                    )\ndemo.launch(share = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:37:28.457091Z","iopub.execute_input":"2022-07-10T14:37:28.457658Z","iopub.status.idle":"2022-07-10T14:37:31.295546Z","shell.execute_reply.started":"2022-07-10T14:37:28.457623Z","shell.execute_reply":"2022-07-10T14:37:31.294656Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}